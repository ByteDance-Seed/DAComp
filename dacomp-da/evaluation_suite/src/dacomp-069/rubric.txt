==============================
I. Final Rubrics (dacomp-069 | Total 38 points)
==============================

1. Requirement 1: Data Scope Verification and Revenue Segmentation Definition (Total 8 points)
   1.1 Criterion 1.1: Time Window and Overall Metric Verification (Max 3 points | deterministic)
       1.1.1 Path 1.1.A [3 points | Comprehensive Dashboard Verification]
           1.1.1.1 Sub-criterion 1.1.A.1 [1 point | Completeness] Must clearly state that the analysis is limited to `package_name='com.dev.photoeditor'` and is based on 12 monthly data points from 2024-01-15 to 2024-12-15 in the `google_play__comprehensive_performance_dashboard` table.
           1.1.1.2 Sub-criterion 1.1.A.2 [1 point | Accuracy] Verification anchors (tolerance ±1 or ±0.005 for decimals): `overall_performance_score` on 2024-01-15 = 85, on 2024-12-15 = 72; full-year average = 76.083; average `quality_score` = 72.8; average `crash_rate_per_1k_devices` = 1.958; average `store_conversion_rate` = 0.1281; average `day_30_retention_rate` = 0.1567; total `research_budget_usd` for the year = $2,000,000.01.
           1.1.1.3 Sub-criterion 1.1.A.3 [1 point | Conclusion] Output the conclusion: despite approximately $2M in budget support, the overall score dropped from 85 to 72, accompanied by a simultaneous decline in quality, stability, retention, and conversion; confirm that subsequent analysis will use the same time window and definitions.
   1.2 Criterion 1.2: Feasibility of Revenue Thresholds and Alternative Approaches (Max 3 points | open)
       1.2.1 Path 1.2.A [3 points | Primary Segmentation by ARPU]
           1.2.1.1 Sub-criterion 1.2.A.1 [1 point | Completeness] Explain that `average_revenue_per_user` (in USD/user) from `google_play__geo_market_analysis` will be used as the primary basis for the ">7 vs ≤7" segmentation.
           1.2.1.2 Sub-criterion 1.2.A.2 [1 point | Accuracy] Provide anchors (tolerance ±0.5%): total sample markets = 14; markets with ARPU > 7 = 13; the only market with ARPU ≤ 7 is Indonesia (ID, $5.08); markets with ARPU < 3 is empty; min = 5.08, max = 68.57, average = 27.47.
           1.2.1.3 Sub-criterion 1.2.A.3 [1 point | Conclusion] State that subsequent analysis will approximate the low-revenue group using "ARPU ≤ 7 (ID only)" and note that the sample size of 1 requires cross-validation with other segmentation methods.
       1.2.2 Path 1.2.B [3 points | Segmentation by Revenue Tier]
           1.2.2.1 Sub-criterion 1.2.B.1 [1 point | Completeness] Explain the use of `revenue_tier` (Tier1/2/3) as a business proxy for `>7M vs <3M`, serving as a proxy segmentation for high-revenue and low-revenue markets.
           1.2.2.2 Sub-criterion 1.2.B.2 [1 point | Accuracy] Verification anchors (tolerance ±1%): Tier1 = 5 markets, `revenue_last_30_days` ≈ $40.95M, average `weekly_growth_rate` ≈ -0.07; Tier2 = 3 markets, ≈ $15.42M, average `weekly_growth_rate` ≈ -0.063; Tier3 = 6 markets, ≈ $12.40M, average `weekly_growth_rate` ≈ +0.067.
           1.2.2.3 Sub-criterion 1.2.B.3 [1 point | Conclusion] State that Tier1/2 represent a mature, high-revenue portfolio, while Tier3 represents an emerging, low-revenue portfolio, which can serve as a robust alternative if the ARPU segmentation is imbalanced, while maintaining consistent conclusions.
       1.2.3 Path 1.2.C [3 points | Segmentation by Net Transaction Value]
           1.2.3.1 Sub-criterion 1.2.C.1 [1 point | Completeness] In `google_play__finance_report`, calculate `net_per_txn = SUM(net_amount)/SUM(transactions)` and attempt to segment using ">7 vs <3".
           1.2.3.2 Sub-criterion 1.2.C.2 [1 point | Accuracy] Anchors (tolerance ±1%): number of countries covered = 6; min(net_per_txn) = 8.257; max = 76.765; average = 31.399; confirm that the <3 bucket is empty and state the need to fall back to ARPU/Tier segmentation.
           1.2.3.3 Sub-criterion 1.2.C.3 [1 point | Conclusion] Explain that "net amount per transaction" is only applicable to transaction-dominant countries, has a small sample size, and ignores ad revenue; describe how this metric connects with geographical KPIs and complements the primary segmentation.
   1.3 Criterion 1.3: Metric Dictionary and Field Mapping (Max 2 points | deterministic)
       1.3.1 Path 1.3.A [2 points | Multi-Table Field Explanation]
           1.3.1.1 Sub-criterion 1.3.A.1 [1 point | Completeness] List the core fields and tables required for the analysis: `geo_market_analysis` (ARPU, retention, churn, conversion, quality, crashes, `revenue_tier`, `region`, etc.), `comprehensive_performance_dashboard` (`overall_performance_score`, `quality_score`, `crash_rate_per_1k_devices`, `store_conversion_rate`, `day_x_retention_rate`, `research_budget_usd`, `daily_net_revenue`, etc.), `finance_report` (`net_amount`, `transactions`, `region`), and `time_series_trends` (as a supplement for trends).
           1.3.1.2 Sub-criterion 1.3.A.2 [1 point | Accuracy] Clarify field definitions: `app_crash_rate_per_1k` = crash rate per 1k devices, `store_conversion_rate` = Store installs / visitors, `average_revenue_per_user` = geographical ARPU, `daily_net_revenue` = daily net revenue, `research_budget_usd` = monthly research investment; emphasize that no data cleaning is performed and the analysis should be reproduced based on the original definitions.

2. Requirement 2: Quantifying the Differences between High-Revenue and Low-Revenue Markets (Total 12 points)
   2.1 Criterion 2.1: Non-Weighted Comparison of Key KPIs Within Groups (Max 5 points | open)
       2.1.1 Path 2.1.A [5 points | ARPU > 7 vs ARPU ≤ 7]
           2.1.1.1 Sub-criterion 2.1.A.1 [1 point | Completeness] For both groups, calculate: ARPU, `avg_transaction_value` (ATV), `avg_daily_revenue`, `avg_daily_installs`, `avg_active_devices`, `weekly_growth_rate`, D1/D7/D30 retention, `daily_churn_rate`, `store_conversion_rate`, quality score, crash rate, `overall_market_score`, and total `revenue_last_30_days`.
           2.1.1.2 Sub-criterion 2.1.A.2 [3 points | Accuracy] Anchors (tolerance ≤±1%): Top group (13 countries): avg_arpu=29.1938, avg_atv=37.2654, avg_daily_rev≈172,102.56, avg_installs≈4,345.38, avg_active_devices≈209,307.69, avg_weekly_growth=-0.02, avg_d1=0.7123, avg_d7=0.4662, avg_d30=0.2077, avg_churn=0.2877, avg_store_conv=0.0677, avg_quality=68.0154, avg_crash=2.6231, sum_rev_30d=$67.12M, avg_market_score=640.9; Low group (1 country, ID): avg_arpu=5.08, avg_atv=6.85, avg_daily_rev=55,000, avg_installs=8,950, avg_active_devices=325,000, avg_weekly_growth=0.12, avg_d1=0.64, avg_d7=0.40, avg_d30=0.17, avg_churn=0.36, avg_store_conv=0.077, avg_quality=72.1, avg_crash=1.6, sum_rev_30d=$1.65M, avg_market_score=435.9.
           2.1.1.3 Sub-criterion 2.1.A.3 [1 point | Conclusion] Explain the differences: high-ARPU markets lead in monetization and retention but have negative growth and are dragged down by quality and crash issues; low-ARPU markets have good growth and conversion with higher quality, but weak retention and high churn, failing to close the revenue gap.
       2.1.2 Path 2.1.B [4 points | By Revenue Tier (Tier1 vs Tier3)]
           2.1.2.1 Sub-criterion 2.1.B.1 [1 point | Completeness] For Tier1 and Tier3, calculate the same metrics as in 2.1.A, including total `revenue_last_30_days`.
           2.1.2.2 Sub-criterion 2.1.B.2 [2 points | Accuracy] Anchors (tolerance ≤±1%): Tier1 avg_arpu=42.692, avg_atv=58.10, avg_daily_rev=273,000, avg_weekly_growth=-0.07, avg_d30=0.25, avg_churn=0.224, avg_store_conv=0.0688, avg_quality=67.36, avg_crash=2.9, sum_rev_30d=$40.95M, avg_market_score=820.43; Tier3 avg_arpu=8.825, avg_atv=14.0167, avg_daily_rev=68,888.89, avg_weekly_growth=+0.067, avg_d30=0.158, avg_churn=0.367, avg_store_conv=0.0715, avg_quality=70.0, avg_crash=2.0, sum_rev_30d=$12.40M, avg_market_score=432.26.
           2.1.2.3 Sub-criterion 2.1.B.3 [1 point | Conclusion] Point out that Tier1 contributes the most revenue but has negative growth and high quality pressure; Tier3 has a smaller revenue scale but positive growth and weak retention.
       2.1.3 Path 2.1.C [3 points | Quantile-based Segmentation]
           2.1.3.1 Sub-criterion 2.1.C.1 [1 point | Completeness] Use `quantile_cut(ARPU,[0,0.33,0.66,1])` to get Low/Mid/High groups, and record the thresholds Q33=10.3994, Q66=38.5618.
           2.1.3.2 Sub-criterion 2.1.C.2 [1 point | Accuracy] Calculate intra-group KPIs (tolerance ≤±2%): High (5 countries) avg_arpu=47.4540, avg_daily_rev=225,200, avg_installs=2,368, avg_weekly_growth=-0.056, avg_d30=0.236, avg_churn=0.244, avg_store_conv=0.0614, avg_quality=67.22, avg_crash=2.94, sum_rev_30d=$33.78M; Mid (4 countries) avg_arpu=26.3475, avg_daily_rev≈203,666.67, avg_installs=4,542.5, avg_weekly_growth=-0.07, avg_d30=0.22, avg_churn=0.27, avg_store_conv=0.07175, avg_quality=66.925, avg_crash=2.85, sum_rev_30d=$24.44M; Low (5 countries) avg_arpu=8.388, avg_daily_rev≈70,333.33, avg_installs=7,086, avg_weekly_growth=+0.084, avg_d30=0.162, avg_churn=0.36, avg_store_conv=0.0726, avg_quality=70.5, avg_crash=1.92, sum_rev_30d=$10.55M.
           2.1.3.3 Sub-criterion 2.1.C.3 [1 point | Conclusion] Summarize that quantile results are consistent with the primary segmentation: High group performance aligns with the Top group; Mid group is in between and its quality/crash rates are close to High; Low group is similar to Indonesia, with high growth but weak retention.
   2.2 Criterion 2.2: Weighted Metrics and Scale Impact (Max 3 points | open)
       2.2.1 Path 2.2.A [3 points | Weighting by Active Devices/Visitors]
           2.2.1.1 Sub-criterion 2.2.A.1 [1 point | Completeness] Weight D1/D7/D30 retention, daily churn, and quality by `avg_active_devices`, and weight `store_conversion_rate` by `store_visitors_30d`, then compare the ARPU > 7 vs ≤ 7 groups.
           2.2.1.2 Sub-criterion 2.2.A.2 [1 point | Accuracy] Anchors (tolerance ≤±1%): Top group wavg_d1=0.7177, wavg_d7=0.4697, wavg_d30=0.2107, wavg_churn=0.2823, wavg_quality=68.4372, wavg_store_conv=0.07227; Low group wavg_d1=0.64, wavg_d7=0.40, wavg_d30=0.17, wavg_churn=0.36, wavg_quality=72.1, wavg_store_conv=0.077.
           2.2.1.3 Sub-criterion 2.2.A.3 [1 point | Conclusion] Point out that the conclusion remains unchanged after weighting by scale: the high-ARPU markets' retention advantage is more pronounced, but their quality and conversion shortcomings persist; the low group has high quality but fails to drive scale.
       2.2.2 Path 2.2.B [2 points | Verification by Revenue Weighting]
           2.2.2.1 Sub-criterion 2.2.B.1 [1 point | Completeness] Design a weighting scheme for retention, churn, and store conversion using `revenue_last_30_days` and explain the rationale for this choice (aligns with capital return on investment).
           2.2.2.2 Sub-criterion 2.2.B.2 [1 point | Accuracy] Verification anchors (tolerance ≤±1%): Top group revenue-weighted D1/D7/D30 = 0.7471/0.5085/0.23, weighted churn = 0.2529, weighted conversion = 0.06837; Low group metrics remain the same as the original values (0.64/0.40/0.17/0.36/0.077), and state that the directional conclusion is consistent with active device weighting.
   2.3 Criterion 2.3: Geographical Structure Breakdown (Max 4 points | open)
       2.3.1 Path 2.3.A [4 points | Aggregation by Region]
           2.3.1.1 Sub-criterion 2.3.A.1 [1 point | Completeness] For the ARPU > 7 markets, aggregate ARPU, weekly growth, store conversion, D7, D30, churn, quality, crash rate, and 30-day revenue by `region`.
           2.3.1.2 Sub-criterion 2.3.A.2 [2 points | Accuracy] Anchors (tolerance ≤±1%): Europe avg_arpu=34.60, avg_weekly_growth=-0.05, avg_store_conv=0.0628, avg_crash=2.85, sum_rev_30d=$22.37M; North America avg_arpu=23.89, avg_weekly_growth=-0.023, avg_store_conv=0.0723, avg_crash=2.467, sum_rev_30d=$17.68M; Asia avg_arpu=22.895, avg_weekly_growth=-0.01, avg_store_conv=0.07, avg_d7=0.455, avg_d30=0.2025, avg_churn=0.2975, avg_quality=67.45, avg_crash=2.675, sum_rev_30d=$16.74M; Oceania avg_arpu=68.57, avg_weekly_growth=-0.03, avg_store_conv=0.06, avg_crash=2.5, sum_rev_30d=$7.68M; South America avg_arpu=9.3, avg_weekly_growth=+0.08, avg_store_conv=0.072, avg_crash=2.1, sum_rev_30d=$2.65M.
           2.3.1.3 Sub-criterion 2.3.A.3 [1 point | Conclusion] Summarize: European/East Asian (JP/KR) markets have the worst quality and most severe negative growth; North America has moderate negative growth and slightly better quality; South America has a small scale but positive growth, making it a suitable replication model after quality improvements.
       2.3.2 Path 2.3.B [3 points | Top Countries Leaderboard]
           2.3.2.1 Sub-criterion 2.3.B.1 [1 point | Completeness] List the top 10 countries in descending order of `revenue_last_30_days`, displaying `weekly_growth_rate`, `store_conversion_rate`, D30, churn, crash rate, quality, and `investment_recommendation`.
           2.3.2.2 Sub-criterion 2.3.B.2 [1 point | Accuracy] Anchors (tolerance ≤±1%): US $9.85M/-0.08/0.090/0.28/0.18/2.8/68.5 (Maintain); GB $8.45M/-0.07/0.062/0.22/0.27/3.1/66.1 (Quality Focus); JP $7.82M/-0.12/0.07/0.25/0.22/3.2/65.2 (Reduce); AU $7.68M/-0.03/0.06/0.26/0.20/2.5/69.2 (Increase); DE $7.15M/-0.05/0.062/0.24/0.25/2.9/67.8 (Maintain); CA $5.85M/-0.04/0.062/0.23/0.24/2.7/68.8 (Maintain); FR $4.92M/-0.06/0.061/0.21/0.28/3.0/66.5 (Quality Focus); KR $4.65M/-0.09/0.061/0.23/0.26/3.5/64.2 (Reduce); IN $2.85M/+0.15/0.089/0.18/0.32/1.8/71.5 (Increase); BR $2.65M/+0.08/0.072/0.16/0.35/2.1/69.8 (Maintain).
           2.3.2.3 Sub-criterion 2.3.B.3 [1 point | Conclusion] Identify priority countries for fixing quality issues (GB/JP/KR/FR) and growth models (IN/BR/AU), and cross-reference these findings with the existing `investment_recommendation`.

3. Requirement 3: Performance Decline Drivers and Capital Efficiency Validation (Total 10 points)
   3.1 Criterion 3.1: Time Series and Quality Deterioration Validation (Max 3 points | deterministic)
       3.1.1 Path 3.1.A [3 points | Monthly Comparison]
           3.1.1.1 Sub-criterion 3.1.A.1 [1 point | Completeness] Display for Jan 2024 and Dec 2024: `overall_performance_score`, `quality_score`, `crash_rate_per_1k_devices`, `store_conversion_rate`, `day_7_retention_rate`, `day_30_retention_rate`, `daily_churn_rate`, `version_fragmentation`, `total_issues_per_1k_devices`, `daily_anrs`, `daily_crashes`, `research_budget_usd`, `daily_net_revenue`, and `active_devices`.
           3.1.1.2 Sub-criterion 3.1.A.2 [1 point | Accuracy] Anchors (tolerance ±1 or ±0.005): Values for 2024-01-15 are 85/81.2/1.0/0.14/0.48/0.22/0.32/12/1.4/740/1,850/$166,666.67/$285,000/1,850,000; Values for 2024-12-15 are 72/65.2/3.2/0.12/0.24/0.10/0.65/23/4.48/1,785/4,460/$150,000/$146,000/1,395,000.
           3.1.1.3 Sub-criterion 3.1.A.3 [1 point | Conclusion] Point out that the deterioration in quality and stability led to a simultaneous drop in retention and conversion, which is the direct cause of the decline in overall performance score.
   3.2 Criterion 3.2: Key KPI Correlation and Driver Analysis (Max 4 points | open)
       3.2.1 Path 3.2.A [4 points | Pearson Correlation]
           3.2.1.1 Sub-criterion 3.2.A.1 [1 point | Completeness] Explain the use of correlation analysis between `average_revenue_per_user` and `weekly_growth_rate`, `day_7_retention_rate`, `day_30_retention_rate`, `daily_churn_rate`, `store_conversion_rate`, `app_crash_rate_per_1k`. Must provide reproducible formulas or code steps (mean → covariance → standard deviation).
           3.2.1.2 Sub-criterion 3.2.A.2 [2 points | Accuracy] Correlation coefficient anchors (tolerance ±0.02): corr(arpu, weekly_growth)=-0.673; corr(arpu, d7)=+0.766; corr(arpu, d30)=+0.736; corr(arpu, churn)=-0.745; corr(arpu, store_conv)=-0.523; corr(arpu, crash)=+0.687.
           3.2.1.3 Sub-criterion 3.2.A.3 [1 point | Conclusion] State that high-ARPU markets have strong retention and value but face growth pressure, with crashes and low conversion creating a structural imbalance; low-ARPU markets show the opposite pattern.
       3.2.2 Path 3.2.B [3 points | Crashes vs. Growth/Conversion]
           3.2.2.1 Sub-criterion 3.2.B.1 [1 point | Completeness] In the ARPU > 7 subset, analyze the correlation or use threshold-based segmentation to examine the relationship between `app_crash_rate_per_1k` and `weekly_growth_rate`/`store_conversion_rate`, providing weighted or scatter plot verification.
           3.2.2.2 Sub-criterion 3.2.B.2 [1 point | Accuracy] Correlation coefficient anchors (tolerance ±0.02): corr(crash, weekly_growth)=-0.913, corr(crash, store_conv)=-0.323; If using threshold segmentation, must demonstrate that the high-crash group has significantly lower weekly growth and conversion.
           3.2.2.3 Sub-criterion 3.2.B.3 [1 point | Conclusion] Summarize that deteriorating stability significantly inhibits new user acquisition and funnel performance, providing a key explanation for the negative growth in high-ARPU markets.
       3.2.3 Path 3.2.C [3 points | Regression/Causal Inference Approach]
           3.2.3.1 Sub-criterion 3.2.C.1 [1 point | Completeness] Construct a model `weekly_growth ~ crash + store_conv + quality + churn` (can include `region` dummy variables), explaining variable selection and how to handle multicollinearity (e.g., standardization, VIF check).
           3.2.3.2 Sub-criterion 3.2.C.2 [1 point | Accuracy] Provide the fitting process (e.g., standardization → linear regression or Lasso → leave-one-out or K-fold cross-validation), and verify that coefficient signs are consistent with correlation analysis (crash, churn are negative; store_conv, quality are positive).
           3.2.3.3 Sub-criterion 3.2.C.3 [1 point | Conclusion] Quantify driver strength (e.g., a 1-point reduction in `app_crash_rate_per_1k` could lead to a `weekly_growth` increase of ~|β_crash|), and cross-validate with the correlation analysis.
   3.3 Criterion 3.3: Capital Efficiency and ROI Measurement (Max 3 points | open)
       3.3.1 Path 3.3.A [3 points | Revenue-to-Budget Comparison]
           3.3.1.1 Sub-criterion 3.3.A.1 [1 point | Completeness] Define `ROI_tier = (sum_rev_30d * 12) / research_budget_allocated`, and explain that the budget is allocated based on the share of 30-day revenue (total revenue $68.77M).
           3.3.1.2 Sub-criterion 3.3.A.2 [1 point | Accuracy] Calculation example: Tier1 share = 40.95/68.77 ≈ 59.55%, budget ≈ $1.19M, ROI ≈ 412.62; Tier2 share ≈ 22.42%, budget ≈ $0.45M, ROI ≈ 412.62; Tier3 share ≈ 18.03%, budget ≈ $0.36M, ROI ≈ 412.62; Explain that the identical ROI is a result of allocation by revenue share.
           3.3.1.3 Sub-criterion 3.3.A.3 [1 point | Conclusion] Point out that if the budget is not allocated by revenue, ROI will deviate, and investment should shift towards high-ROI markets; recommend setting an ROI threshold (e.g., review if <350) and validating capital efficiency in conjunction with a quality improvement plan.
       3.3.2 Path 3.3.B [2 points | Scenario Sensitivity Analysis]
           3.3.2.1 Sub-criterion 3.3.B.1 [1 point | Completeness] Design scenarios: ① High-ARPU markets' crash rate decreases by 30% (from ~2.62 to 1.83), ② Store conversion increases by 200bps (from 0.0677 to 0.0877), and explain the model for estimating the impact on revenue and overall performance score.
           3.3.2.2 Sub-criterion 3.3.B.2 [1 point | Accuracy] Use reproducible calculation logic and state assumptions, such as ΔRevenue ≈ baseline_revenue * (Δconversion / baseline_conversion) and mapping the change in overall performance score to the correlation with quality/crashes (e.g., a 1-point increase in quality score leads to a ~0.5-point increase in overall score).

4. Requirement 4: Differentiated Action Plans and KPI Closed-Loop System (Total 8 points)
   4.1 Criterion 4.1: Strategy for High-ARPU, Mature Markets (Max 4 points | open)
       4.1.1 Path 4.1.A [4 points | Quality and Funnel Repair]
           4.1.1.1 Sub-criterion 4.1.A.1 [1 point | Completeness] Propose at least 3 actions for high-ARPU markets like Europe/JP/KR/GB/US (e.g., fixing crash hotspots, setting up canary release with rollback thresholds, A/B testing store assets, paywall conversion optimization, automated win-back campaigns).
           4.1.1.2 Sub-criterion 4.1.A.2 [2 points | Accuracy] Link actions to goals and align with anchors: reduce `app_crash_rate_per_1k` from the current 2.6–3.5 to ≤1.8 (≤2.0 within 90 days), increase `store_conversion_rate` from 0.0677 to ≥0.075, lift `weekly_growth_rate` from -0.02 to ≥0, improve D30 retention from 0.21 to ≥0.24, and raise quality score from ≈68 to ≥72; must specify which countries and actions correspond to each metric.
           4.1.1.3 Sub-criterion 4.1.A.3 [1 point | Conclusion] Provide an execution timeline (e.g., 4 weeks for stability fixes → 8 weeks for conversion experiments → quarterly ROI review) and an expected recovery of the overall performance score to ≥76 within 1-2 quarters.
       4.1.2 Path 4.1.B [3 points | Market Portfolio Reallocation]
           4.1.2.1 Sub-criterion 4.1.B.1 [1 point | Completeness] Based on `investment_recommendation`, define a tiered logic for increasing investment (AU/IN/ID/MX if extended), maintaining (US/DE/CA/BR), and reducing (JP/KR/RU if present).
           4.1.2.2 Sub-criterion 4.1.B.2 [1 point | Accuracy] Set budget reallocation ratios (e.g., 60% for high-ARPU quality repair, 30% for emerging growth markets, 10% for platform capabilities) and align with KPI thresholds (`app_crash_rate_per_1k` ≤ 2.0, `store_conversion_rate` ≥ 0.075, D30 ≥ 0.24, ROI ≥ 420).
           4.1.2.3 Sub-criterion 4.1.B.3 [1 point | Conclusion] State the expected outcomes after reallocation: overall performance score recovery, revenue returning to positive growth, and ROI improvement, and establish a monthly ROI/KPI review mechanism.
   4.2 Criterion 4.2: Strategy for Low-ARPU, Emerging Markets (Max 4 points | open)
       4.2.1 Path 4.2.A [4 points | Localization and Monetization Enhancement]
           4.2.1.1 Sub-criterion 4.2.A.1 [1 point | Completeness] Propose at least 3 strategies for markets like Indonesia/India/Brazil/Mexico (e.g., localized pricing tiers, lightweight subscriptions and microtransactions, expanding payment channels, feature onboarding, viral incentives).
           4.2.1.2 Sub-criterion 4.2.A.2 [2 points | Accuracy] Set quantitative goals and align with the current state: for ID, increase ARPU from 5.08 to ≥6.5, D30 retention from 0.17 to ≥0.20, and maintain weekly growth ≥+10%; for IN, ARPU from 7.4 to ≥8.5, D30 ≥0.21, `store_conversion_rate` ≥0.089; for BR/MX, maintain weekly growth ≥+5%, ARPU ≥8, `app_crash_rate_per_1k` ≤1.8; ensure targets are reasonable and trackable relative to baselines.
           4.2.1.3 Sub-criterion 4.2.A.3 [1 point | Conclusion] Explain how this forms a "two-pronged approach" with the high-ARPU fixes: pilot in IN/ID first → evaluate after 8 weeks → expand to BR/MX upon success, and define acceptance criteria (scale up after ARPU and retention targets are met).
       4.2.2 Path 4.2.B [3 points | Trial Period and KPI Dashboard]
           4.2.2.1 Sub-criterion 4.2.B.1 [1 point | Completeness] Design quarterly trial period metrics, including `app_crash_rate_per_1k`, `store_conversion_rate`, `weekly_growth_rate`, ARPU, and ROI, and set thresholds and pause rules.
           4.2.2.2 Sub-criterion 4.2.B.2 [1 point | Accuracy] KPI dashboard proposal: update monthly with example thresholds—`app_crash_rate_per_1k` ≤ 1.8, `store_conversion_rate` ≥ 0.077, `weekly_growth_rate` ≥ +5%, ARPU meeting market-specific goals, ROI ≥ 350; if targets are not met for 2 consecutive periods, pause scaling or adjust strategy.
           4.2.2.3 Sub-criterion 4.2.B.3 [1 point | Conclusion] Explain how this dashboard creates a capital efficiency closed-loop: enabling timely stop-loss, retaining high-ROI actions, and establishing a strategic iteration cadence.
